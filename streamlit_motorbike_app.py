import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import streamlit as st
import pandas as pd
from sklearn.preprocessing import StandardScaler

from modules.loader import load_data, load_model, load_data_cluster
from modules.recommender import get_recommendations, get_text_recommendations
from modules.text_preprocess import text_preprocess



# ---------------------- DATA DEMO ----------------------
# Dummy data cho ph√¢n c·ª•m
np.random.seed(42)
df_demo = pd.DataFrame({
    "Gi√°": np.random.randint(15, 80, 80),
    "Km": np.random.randint(5000, 60000, 80),
    "Dung t√≠ch": np.random.choice([110, 125, 150], 80),
})
# G√°n c·ª•m gi·∫£ l·∫≠p
df_demo["cluster"] = np.random.randint(0, 3, 80)

# Dummy dataset cho content-based
motorbikes = pd.DataFrame({
    "name": ["Honda Vision", "Yamaha Sirius", "Honda AirBlade", "Yamaha Janus", "Honda Lead"],
    "brand": ["Honda", "Yamaha", "Honda", "Yamaha", "Honda"],
    "engine": [110, 110, 125, 110, 125],
    "price": [28, 20, 40, 30, 38],
    "description": [
        "Xe tay ga nh·ªè g·ªçn ti·∫øt ki·ªám xƒÉng",
        "Xe s·ªë ph·ªï th√¥ng b·ªÅn b·ªâ gi√° r·∫ª",
        "Xe tay ga cao c·∫•p m·∫°nh m·∫Ω",
        "Xe tay ga nh·∫π nh√†ng ph√π h·ª£p n·ªØ",
        "Xe tay ga r·ªông r√£i c·ªëp l·ªõn",
    ],
})

# t·∫°o vector m√¥ ph·ªèng similarity
motorbikes["desc_vec"] = motorbikes.index

# ---------------------- APP ----------------------
def main():

    st.set_page_config(page_title="Motorbike Recommendation", layout="wide")
    #st.title("Trung T√¢m Tin H·ªçc")
    st.image("xe_may_cu.png", caption="Ch·ª£ mua b√°n xe m√°y c≈©")
    # ---------- SIDEBAR WITH LOGO & INFO ----------
    #st.sidebar.image("xe_may_cu.png", width=80)
    st.sidebar.title("üöÄ Menu")

    menu = st.sidebar.radio(
        "Click ch·ªçn n·ªôi dung:",
        [
            "Gi·ªõi thi·ªáu",
            "B√°o c√°o ƒë√°nh gi√°",
            "C√°c ph√¢n kh√∫c xe",
            "T√¨m ki·∫øm xe",
            "Th√¥ng tin nh√≥m th·ª±c hi·ªán"
        ]
    )

    # ---------- BUSINESS PROBLEM ----------
    if menu == "Gi·ªõi thi·ªáu":
        st.title("üìå Gi·ªõi thi·ªáu t·ªïng quan")
        st.markdown(
            """
            ### B·ªëi c·∫£nh
            Ng∆∞·ªùi mua xe m√°y c≈© g·∫∑p nhi·ªÅu kh√≥ khƒÉn v√¨ th·ªã tr∆∞·ªùng ƒëa d·∫°ng, gi√° ch√™nh l·ªách v√† th√¥ng tin thi·∫øu minh b·∫°ch. n·ªÅn t·∫£ng giao d·ªãch xe uy t√≠n, l√† c·∫ßu n·ªëi tin c·∫≠y gi·ªØa ng∆∞·ªùi mua v√† ng∆∞·ªùi b√°n tr√™n to√†n qu·ªëc. 
            V·ªõi l·ª£i th·∫ø ‚ÄúD·ªÖ t√¨m - D·ªÖ mua‚Äù, Ch·ª£ T·ªët Xe kh√¥ng ng·ª´ng ho√†n thi·ªán d·ªãch v·ª• v·ªõi th√¥ng tin minh b·∫°ch, quy tr√¨nh ƒëƒÉng tin ƒë∆°n gi·∫£n v√† kh·∫£ nƒÉng t√¨m xe nhanh ch√≥ng, ƒë√∫ng nhu c·∫ßu.
            Th·ªã tr∆∞·ªùng xe m√°y t·∫°i Vi·ªát Nam ƒëang ph√°t tri·ªÉn m·∫°nh m·∫Ω v·ªõi s·ª± ƒëa d·∫°ng v·ªÅ m·∫´u m√£, ph√¢n kh√∫c v√† th∆∞∆°ng hi·ªáu, ƒë√°p ·ª©ng nhu c·∫ßu di chuy·ªÉn ng√†y c√†ng cao c·ªßa ng∆∞·ªùi ti√™u d√πng. T√πy thu·ªôc v√†o s·ªü th√≠ch v√† nhu c·∫ßu s·ª≠ d·ª•ng, b·∫°n c√≥ th·ªÉ ch·ªçn mua xe theo c√°c ph√¢n lo·∫°i nh∆∞ xe s·ªë, xe tay ga, xe c√¥n tay hay xe moto ph√¢n kh·ªëi l·ªõn. Ng∆∞·ªùi d√πng c≈©ng c√≥ th·ªÉ l·ª±a ch·ªçn theo dung t√≠ch xe nh∆∞ xe 50cc, xe t·ª´ 100 - 175cc,... ƒë·ªÉ ph√π h·ª£p nhu c·∫ßu di chuy·ªÉn c·ªßa m√¨nh.

            ### M·ª•c ti√™u d·ª± √°n
            - X√¢y d·ª±ng h·ªá th·ªëng g·ª£i √Ω xe m√°y c≈© ph√π h·ª£p nhu c·∫ßu.
            - S·ª≠ d·ª•ng model g·ª£i √Ω d·ª±a tr√™n n·ªôi dung ƒë·ªÉ ƒë·ªÅ xu·∫•t xe t∆∞∆°ng t·ª± xe c·∫ßn t√¨m v√† ph√¢n c·ª•m nh·∫±m x√°c ƒë·ªãnh xe thu·ªôc ph√¢n kh√∫c n√†o.
            - Hi·ªÉn th·ªã ph√¢n t√≠ch d·ªØ li·ªáu, b√°o c√°o hi·ªáu su·∫•t m√¥ h√¨nh.
            """
        )

    # ---------- EVALUATION (A + C) ----------
    elif menu == "B√°o c√°o ƒë√°nh gi√°":

        st.title("B√°o c√°o m√¥ h√¨nh g·ª£i √Ω d·ª±a tr√™n n·ªôi dung v√† ph√¢n c·ª•m")

        st.markdown("""
        ## üìù **B√ÅO C√ÅO M√î H√åNH G·ª¢I √ù D·ª∞A TR√äN N·ªòI DUNG **

        ### üéØ **1. M·ª•c ti√™u h·ªá th·ªëng**
        H·ªá th·ªëng ƒë∆∞·ª£c x√¢y d·ª±ng nh·∫±m g·ª£i √Ω c√°c xe m√°y t∆∞∆°ng t·ª± d·ª±a tr√™n th√¥ng tin m√¥ t·∫£ c·ªßa t·ª´ng xe. Vi·ªác g·ª£i √Ω **d·ª±a ho√†n to√†n tr√™n n·ªôi dung** c·ªßa c√°c c·ªôt Th∆∞∆°ng hi·ªáu, D√≤ng xe, M√¥ t·∫£ chi ti·∫øt c·ªßa c√°c xe ƒë√£ ƒëƒÉng t·∫£i.

        ---

        ### ‚öôÔ∏è **2. Quy tr√¨nh x√¢y d·ª±ng m√¥ h√¨nh**

        #### **2.1. Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu**
        - L√†m s·∫°ch vƒÉn b·∫£n: vi·∫øt th∆∞·ªùng, lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát, stopwords.
        - Chu·∫©n h√≥a n·ªôi dung m√¥ t·∫£.
        - Vector h√≥a d·ªØ li·ªáu ph·ª•c v·ª• t√≠nh to√°n.

        #### **2.2. C√°c ph∆∞∆°ng ph√°p vector h√≥a ƒë√£ th·ª≠ nghi·ªám**
        1. **Gensim TF-IDF**
        - S·ª≠ d·ª•ng TF-IDF, t√≠nh t∆∞∆°ng t·ª± b·∫±ng Gensim Similarity.
        - K·∫øt qu·∫£ kh√° nh∆∞ng t·ªëc ƒë·ªô kh√¥ng t·ªëi ∆∞u khi d·ªØ li·ªáu l·ªõn.

        2. **Sklearn TF-IDF + Cosine Similarity**
        - T√≠nh to√°n nhanh.
        - D·ªÖ tri·ªÉn khai, d·ªÖ l∆∞u v√† t·∫£i m√¥ h√¨nh.
        - ƒê·ªô ch√≠nh x√°c g·ª£i √Ω cao v√† ·ªïn ƒë·ªãnh.

        ---

        ### üìä **3. ƒê√°nh gi√° m√¥ h√¨nh**

        | Ti√™u ch√≠ | Gensim | Cosine Similarity |
        |---------|--------|--------------------|
        | T·ªëc ƒë·ªô x·ª≠ l√Ω cho 5 ƒë·ªÅ xu·∫•t| Trung b√¨nh 30.6718 gi√¢y| **R·∫•t nhanh** 0.0101 gi√¢y |
        | ƒê·ªô ·ªïn ƒë·ªãnh | Kh√° | **T·ªët** |
        | ƒê·ªô ch√≠nh x√°c qua ƒë√°nh gi√° c√°c n·ªôi dung g·ª£i √Ω v√† qua gi√° tr·ªã similarity trung b√¨nh | T·ªët | **T·ªët nh·∫•t** |
        """)
        st.image("sosanh.png")
        st.markdown("""
        ---

        ### üèÜ **4. L√Ω do ch·ªçn Cosine l√†m m√¥ h√¨nh ch√≠nh**
        - Nhanh, ph√π h·ª£p d·ªØ li·ªáu l·ªõn.
        - ƒê·ªô ch√≠nh x√°c g·ª£i √Ω ·ªïn ƒë·ªãnh.
        - Ph√π h·ª£p cho d·∫°ng d·ªØ li·ªáu m√¥ t·∫£ xe m√°y.

        ---

        ### üöÄ **5. K·∫øt lu·∫≠n**
        Trang web s·ª≠ d·ª•ng **TF-IDF + Cosine Similarity** l√†m m√¥ h√¨nh ch√≠nh v√¨ t√≠nh hi·ªáu qu·∫£, ch√≠nh x√°c v√† t·ªëc ƒë·ªô cao, ƒë·∫£m b·∫£o tr·∫£i nghi·ªám t·ªët cho ng∆∞·ªùi d√πng.

        """)



        st.markdown("""
        ## üìù **B√ÅO C√ÅO M√î H√åNH PH√ÇN C·ª§M **

        ### üéØ **1. M·ª•c ti√™u h·ªá th·ªëng**
        H·ªá th·ªëng ƒë∆∞·ª£c x√¢y d·ª±ng nh·∫±m ph√¢n c·ª•m xe m√°y th√†nh c√°c c·ª•m t∆∞∆°ng ƒë·ªìng d·ª±a tr√™n Th∆∞∆°ng hi·ªáu, D√≤ng xe, S·ªë km ƒëi ƒë∆∞·ª£c v√† Dung t√≠ch xe.

        ---

        ### ‚öôÔ∏è **2. Quy tr√¨nh x√¢y d·ª±ng m√¥ h√¨nh**

       """)
        st.image("Mohinhphancum.png")
        
        st.markdown("""
        ---

        ### üìä **3. ƒê√°nh gi√° m√¥ h√¨nh**

        Theo gi√° tr·ªã Silhouette t√≠nh ƒë∆∞·ª£c gi·ªØa c√°c m√¥ h√¨nh, m√¥ h√¨nh tr√™n sklearn cho k·∫øt qu·∫£ t·ªët h∆°n tr√™n pyspark v√† Agglomerative Clustering cho gi√° tr·ªã t·ªët nh·∫•t.
        """)
        st.image("DGmohinhphancum.png")
        st.markdown("""
        ---

        ### üèÜ **4. L√Ω do ch·ªçn Agglomerative l√†m m√¥ h√¨nh ch√≠nh**
        - Gi√° tr·ªã Silhouette cho ra t·ªët nh·∫•t
        - C√°c c·ª•m ƒë∆∞·ª£c ph√¢n r√µ r√†ng, kh√¥ng b·ªã ch·ªìng l·∫•n.

        ---

        ### üöÄ **5. K·∫øt lu·∫≠n**
        Trang web s·ª≠ d·ª•ng **Aggomerative** l√†m m√¥ h√¨nh ch√≠nh v√¨ c√°c c·ª•m ƒë∆∞·ª£c ph√¢n r√µ r√†ng.

        """)

    # ---------- EVALUATION (A + C) ----------
    elif menu == "C√°c ph√¢n kh√∫c xe":
        df_cluster = load_data_cluster()
        X = df_cluster[['Gi√°', 'S·ªë Km ƒë√£ ƒëi', 'Dung t√≠ch xe_encoded', 'NƒÉm ƒëƒÉng k√Ω']].dropna()
        # chu·∫©n h√≥a d·ªØ li·ªáu
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        st.title("üìä Evaluation & Clustering Report")

        st.subheader("Bi·ªÉu ƒë·ªì Ph√¢n C·ª•m (PCA 2D)")

        # PCA 2D
        pca = PCA(n_components=2)
        X_pca = pca.fit_transform(X_scaled)
        df_cluster["pca1"] = X_pca[:, 0]
        df_cluster["pca2"] = X_pca[:, 1]

        centroids = df_cluster.groupby('agg_cluster')[['pca1', 'pca2']].mean()
        # centroids


        fig, ax = plt.subplots()
        scatter = ax.scatter(df_cluster["pca1"], df_cluster["pca2"], c=df_cluster["cluster"], alpha = 0.3)
        ax.set_xlabel("PCA 1")
        ax.set_ylabel("PCA 2")

        # Ghi nh√£n centroid
        for idx, row in centroids.iterrows():
            ax.text(row['pca1'], row['pca2'], 'x', fontsize=12, weight='bold')

        st.pyplot(fig)

        # --- C. M√¥ t·∫£ c·ª•m ---
        st.subheader("üìå M√¥ t·∫£ c√°c c·ª•m (Cluster Summary)")
        st.markdown(
            """
            **C·ª•m 0:** Xe c√≥ m·ª©c gi√° nh·ªè h∆°n 100tr, qu√£ng ƒë∆∞·ªùng ƒë√£ ƒëi < ~300km, dung t√≠ch 175cc, ph√π h·ª£p v·ªõi nhu c·∫ßu th√¥ng th∆∞·ªùng.  
            **C·ª•m 1:** Xe gi√° r·∫ª v√† s·ªë km ƒë√£ ƒëi > 300km.  
            **C·ª•m 2:** Xe ph√¢n kh·ªëi l·ªõn v√† gi√° cao.  
            """
        )

        st.subheader("üìà Ph√¢n b·ªë gi√° theo t·ª´ng c·ª•m")
        fig2, ax2 = plt.subplots(figsize=(3, 2))
        for cl in df_cluster["cluster"].unique():
            ax2.hist(df_cluster[df_cluster.cluster == cl]["Gi√°"], alpha=0.5, label=f"Cluster {cl}")
        ax2.legend()
        ax2.set_title("Ph√¢n b·ªë Gi√° theo t·ª´ng c·ª•m")
        ax2.set_xlabel("Gi√° (tri·ªáu VNƒê)")
        st.pyplot(fig2)


        fig3, ax3 = plt.subplots(figsize=(3, 2))
        for cl in df_cluster["cluster"].unique():
            ax3.hist(df_cluster[df_cluster.cluster == cl]["S·ªë Km ƒë√£ ƒëi"], alpha=0.5, label=f"Cluster {cl}")
        # ƒë·ªïi nh√£n tr·ª•c ho√†nh sang tri·ªáu km
        xticks = ax3.get_xticks()
        ax3.set_xticks(xticks)
        ax3.set_xticklabels([f"{x/1_000_000:.1f}" for x in xticks])
        ax3.legend()
        ax3.set_title("Ph√¢n b·ªë s·ªë km ƒë√£ ƒëi theo t·ª´ng c·ª•m")
        ax3.set_xlabel("S·ªë Km ƒë√£ ƒëi (tri·ªáu km)")
        st.pyplot(fig3)


        st.image("namdungtichcluster.png")

    # ---------- RECOMMENDATION (B) ----------
    elif menu == "T√¨m ki·∫øm xe":
        st.title("üîç G·ª£i √Ω theo Content-Based Filtering")

        # --- LOAD D·ªÆ LI·ªÜU ---
        df = load_data()
        df_cluster = load_data_cluster()
        model = load_model()  # cosine similarity matrix
        # df = pd.read_csv("cho_tot_cleaned_wt.csv")
       

        # st.subheader("üìã Danh s√°ch xe m√°y")
        # st.write("Ch·ªçn m·ªôt xe ƒë·ªÉ xem th√¥ng tin v√† g·ª£i √Ω:")

        # ===========================
        #  Ch·ªçn ch·∫ø ƒë·ªô
        # ===========================
        mode = st.radio(
            "Ch·ªçn ph∆∞∆°ng th·ª©c g·ª£i √Ω:",
            ["Ch·ªçn t·ª´ danh s√°ch", "T√¨m theo n·ªôi dung nh·∫≠p v√†o"]
        )

        # ===========================
        #  MODE 1: CH·ªåN T·ª™ DANH S√ÅCH
        # ===========================
        if mode == "Ch·ªçn t·ª´ danh s√°ch":
            st.markdown("L·ªçc danh s√°ch xe theo th∆∞∆°ng hi·ªáu v√† m·ª©c gi√°:")
            
            brand_list = ["T·∫•t c·∫£"] + sorted(df['Th∆∞∆°ng hi·ªáu'].dropna().unique().tolist())
            brand = st.selectbox("Th∆∞∆°ng hi·ªáu mong mu·ªën", brand_list)

            price_range = st.slider("Kho·∫£ng gi√° (tri·ªáu)", 15, 200, (20, 50))
                          
            st.subheader("üìã Ch·ªçn xe t·ª´ danh s√°ch")
            # Danh s√°ch ti√™u ƒë·ªÅ xe ƒë·ªÉ ng∆∞·ªùi d√πng ch·ªçn
            if brand != "T·∫•t c·∫£":
                df_filtered = df[df["Th∆∞∆°ng hi·ªáu"] == brand]
            else: df_filtered = df
            # Filter theo gi√°
            df_filtered = df_filtered[(df_filtered['Gi√°']>= price_range[0]) & (df_filtered['Gi√°'] <= price_range[1])]
            xe_list = df_filtered['Ti√™u ƒë·ªÅ'].tolist()
            if len(xe_list) > 0:

                selected_xe = st.selectbox("Ch·ªçn m·ªôt xe ƒë·ªÉ xem th√¥ng tin v√† g·ª£i √Ω t∆∞∆°ng t·ª±", xe_list)

                # T√¨m index c·ªßa xe ƒë∆∞·ª£c ch·ªçn
                selected_index = df.index[df['Ti√™u ƒë·ªÅ'] == selected_xe][0]

                # # L·∫•y th√¥ng tin xe ƒë√£ ch·ªçn
                selected_row = df.loc[selected_index]

                # T√¨m xe t∆∞∆°ng ·ª©ng trong df_cluster
                matched = df_cluster[df_cluster['Ti√™u ƒë·ªÅ'] == selected_xe]
                if len(matched) > 0:
                    cluster_value = matched.iloc[0]['agg_cluster']
                    if cluster_value ==0:
                        st.success(f"üöó Xe n√†y thu·ªôc **c·ª•m {cluster_value}**: ƒëa s·ªë xe thu·ªôc ph√¢n kh√∫c n√†y, bao g·ªìm c√°c d√≤ng xe th√¥ng d·ª•ng, s·ªë km ƒë√£ ƒëi ·ªü m·ª©c trung b√¨nh, thu·ªôc xe c√≥ ph√¢n kh·ªëi < 175cc")
                    if cluster_value ==1:
                        st.success(f"üöó Xe n√†y thu·ªôc **c·ª•m {cluster_value}**: B·∫°n ƒëang ch·ªçn xe c√≥ ph√¢n kh√∫c gi√° th·∫•p, tuy nhi√™n c√°c xe n√†y ƒë√£ s·ª≠ d·ª•ng r·∫•t nhi·ªÅu, c√≥ s·ªë km ƒëi ƒë∆∞·ª£c r·∫•t cao ")
                    if cluster_value ==2:
                        st.success(f"üöó Xe n√†y thu·ªôc **c·ª•m {cluster_value}**: B·∫°n ƒëang ch·ªçn ph√¢n kh√∫c xe hi·∫øm v√† cao c·∫•p, c√°c xe thu·ªôc ph√¢n kh√∫c n√†y th∆∞·ªùng m·ªõi v√† c√≥ qu√£ng ƒë∆∞·ªùng ƒëi √≠t")
                else:
                    st.warning("‚ö† Xe n√†y **kh√¥ng c√≥ c·ª•m t∆∞∆°ng ·ª©ng** trong d·ªØ li·ªáu ph√¢n c·ª•m.")

                st.write("### **üîç Th√¥ng tin xe ƒë√£ ch·ªçn:**")
                st.json(selected_row.to_dict())
                #st.dataframe(df.iloc[[selected_index]])
                # =====================================
                # G·ªçi model ƒë·ªÉ t√¨m xe t∆∞∆°ng t·ª±
                # =====================================
                # L·∫•y g·ª£i √Ω t·ª´ model
                recommendations = get_recommendations(selected_index, model, df, top_n=5)

                st.write("### üîé G·ª£i √Ω xe t∆∞∆°ng t·ª±:")
                st.dataframe(recommendations)
            else: 
                st.warning("‚ùó Kh√¥ng c√≥ xe ph√π h·ª£p v·ªõi th∆∞∆°ng hi·ªáu v√† m·ª©c gi√° ƒë√£ ch·ªçn.")



        # ===========================
        #  MODE 2: NH·∫¨P N·ªòI DUNG
        # ===========================
        else:
            st.subheader("‚úèÔ∏è Nh·∫≠p n·ªôi dung ƒë·ªÉ t√¨m xe ph√π h·ª£p")

            user_input = st.text_area("Nh·∫≠p m√¥ t·∫£ (vd: xe tay ga, vespa, ch√≠nh ch·ªß...)", value= "vespa sprint ch√≠nh ch·ªß")

            if st.button("T√¨m ki·∫øm"):
                if len(user_input) < 3:
                    st.error("Vui l√≤ng nh·∫≠p n·ªôi dung ƒë·ªß d√†i.")
                else:
                    # =====================================
                    # Model x·ª≠ l√Ω text v√† tr·∫£ k·∫øt qu·∫£
                    # =====================================

                 
                    #user_input_wt = text_preprocess(user_input)
                    # vectorizer = TfidfVectorizer(analyzer='word', stop_words=stop_words)
                    # query_vec = vectorizer.transform([search_str_wt])
                    # #T√≠nh cosine similarity gi·ªØa string text v√† to√†n b·ªô Dataframe
                    # searchtext_cosine_sim = cosine_similarity(query_vec, tfidf_matrix).flatten()
                    # top5_idx = searchtext_cosine_sim.argsort()[::-1][:5]
                    # df[['id', 'Gi√°', 'D√≤ng xe','NƒÉm ƒëƒÉng k√Ω','Lo·∫°i xe','Dung t√≠ch xe', "M√¥ t·∫£ chi ti·∫øt"]].iloc[top5_idx]
                    # df_results = df.iloc[top5_idx].copy()
                    # df_results['cosine_similarity'] = searchtext_cosine_sim[top5_idx]

                    str_recommendations = get_text_recommendations(user_input, df, model, top_n=5)

                    st.write("### üîé K·∫øt qu·∫£ g·ª£i √Ω:")

                    st.dataframe(str_recommendations)


        
        #st.dataframe(recommendations[["id", "title", "description"]])




        # st.title("üîç Recommendation Content-Based")

        # st.markdown("Nh·∫≠p nhu c·∫ßu ƒë·ªÉ g·ª£i √Ω xe ph√π h·ª£p.")

        # brand = st.selectbox("Th∆∞∆°ng hi·ªáu mong mu·ªën", ["Honda", "Yamaha", "Kh√¥ng quan tr·ªçng"])
        # price_range = st.slider("Kho·∫£ng gi√° (tri·ªáu)", 15, 80, (20, 50))
        # keyword = st.text_input("T·ª´ kho√° m√¥ t·∫£ (v√≠ d·ª•: ti·∫øt ki·ªám, m·∫°nh m·∫Ω, nh·∫π nh√†ng)")

            

        # if st.button("G·ª£i √Ω ngay"):
        #     df = motorbikes.copy()

        #     # Filter theo gi√°
        #     df = df[(df.price >= price_range[0]) & (df.price <= price_range[1])]

        #     # Filter theo brand
        #     if brand != "Kh√¥ng quan tr·ªçng":
        #         df = df[df.brand == brand]

        #     # M√¥ ph·ªèng cosine similarity
        #     if keyword:
        #         scores = []
        #         for desc in df.description:
        #             sim = len(set(keyword.split()) & set(desc.split()))  # m√¥ ph·ªèng ƒë∆°n gi·∫£n
        #             scores.append(sim)
        #         df["similarity"] = scores
        #         df = df.sort_values("similarity", ascending=False)

        #     st.subheader("‚ú® Top Xe G·ª£i √ù")
        #     st.table(df[["name", "brand", "engine", "price"]])
        
        

    # ---------- TEAM INFO (D) ----------
    else:
        st.title("üë• Th√¥ng tin nh√≥m th·ª±c hi·ªán")

        st.markdown(
            """
            ### Nh√≥m d·ª± √°n Recommendation Motorbike
            - Nguy·ªÖn Ng·ªçc Giao ‚Äì GUI Project 1
            - Nguy·ªÖn Th·ªã Tuy·ªÉn ‚Äì GUI Project 2
        
            ### Ng√†y th·ª±c hi·ªán
            üíª 22/11/2025
            """
        )


if __name__ == "__main__":
    main()
